name: backtest-gates

on:
  workflow_dispatch:
    inputs:
      PROFIT_TARGET:
        description: "profit target (e.g. 0.10)"
        required: true
        default: "0.10"
      HOLDING_DAYS:
        description: "max holding days (e.g. 40)"
        required: true
        default: "40"
      STOP_LEVEL:
        description: "stop level (e.g. -0.10)"
        required: true
        default: "-0.10"
      MAX_EXTEND_DAYS:
        description: "extend horizon tag + strategy label horizon add (e.g. 30)"
        required: true
        default: "30"

      # gate 실험용 리스트
      TAIL_MAX_LIST:
        description: "comma-separated p_tail thresholds (e.g. 0.15,0.25,0.35)"
        required: true
        default: "0.20,0.30"
      U_QUANTILE_LIST:
        description: "comma-separated utility quantiles (e.g. 0.60,0.75,0.90)"
        required: true
        default: "0.75,0.90"
      RANK_BY_LIST:
        description: "comma-separated rank metric (utility|ret_score|p_success). e.g. utility,ret_score"
        required: true
        default: "utility"

      LAMBDA_TAIL:
        description: "utility tail penalty lambda (e.g. 0.05)"
        required: true
        default: "0.05"

      # 캐시 무시하고 강제 재생성
      REFRESH_DATA:
        description: "true to rebuild prices/features/labels/models from scratch"
        required: true
        default: "false"

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      PROFIT_TARGET: ${{ inputs.PROFIT_TARGET }}
      HOLDING_DAYS: ${{ inputs.HOLDING_DAYS }}
      STOP_LEVEL: ${{ inputs.STOP_LEVEL }}
      MAX_EXTEND_DAYS: ${{ inputs.MAX_EXTEND_DAYS }}

      TAIL_MAX_LIST: ${{ inputs.TAIL_MAX_LIST }}
      U_QUANTILE_LIST: ${{ inputs.U_QUANTILE_LIST }}
      RANK_BY_LIST: ${{ inputs.RANK_BY_LIST }}
      LAMBDA_TAIL: ${{ inputs.LAMBDA_TAIL }}

      REFRESH_DATA: ${{ inputs.REFRESH_DATA }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-py311-v1

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install numpy pandas scikit-learn joblib yfinance pyarrow

      # TAG 계산(파일명/머지용)
      - name: Compute TAG
        run: |
          python - <<PY
          pt=float("${PROFIT_TARGET}")
          h=int("${HOLDING_DAYS}")
          sl=float("${STOP_LEVEL}")
          ex=int("${MAX_EXTEND_DAYS}")
          pt_tag=int(round(pt*100))
          sl_tag=int(round(abs(sl)*100))
          tag=f"pt{pt_tag}_h{h}_sl{sl_tag}_ex{ex}"
          with open("${GITHUB_ENV}","a",encoding="utf-8") as f:
              f.write("TAG="+tag+"\\n")
          print("TAG="+tag)
          PY

      - name: Debug list scripts
        run: |
          echo "=== scripts/ ==="
          ls -la scripts || true
          echo "=== data/ ==="
          ls -la data || true

      # ✅ 캐시: prices + features (스크립트/유니버스 바뀌면 무효화)
      - name: Cache static data (prices/features)
        uses: actions/cache@v4
        with:
          path: |
            data/raw/prices.parquet
            data/raw/prices.csv
            data/raw/prices_meta.json
            data/features/**
            data/universe.csv
          key: static-${{ runner.os }}-${{ hashFiles('scripts/fetch_prices.py','scripts/build_features.py','scripts/universe.py','data/universe.csv') }}-v3
          restore-keys: |
            static-${{ runner.os }}-

      # ✅ 캐시: labels + models (TAG별)
      - name: Cache param data (labels/models by TAG)
        uses: actions/cache@v4
        with:
          path: |
            data/labels/**
            data/raw_data.csv
            data/strategy_raw_data.csv
            app/model.pkl
            app/scaler.pkl
            app/tail_model.pkl
            app/tail_scaler.pkl
          key: param-${{ runner.os }}-${{ env.TAG }}-${{ hashFiles('scripts/build_labels.py','scripts/train_model.py','scripts/build_strategy_labels.py','scripts/train_strategy_models.py') }}-v3
          restore-keys: |
            param-${{ runner.os }}-${{ env.TAG }}-

      # REFRESH_DATA=true면 결과물 삭제
      - name: Optional clean (refresh)
        run: |
          if [ "${REFRESH_DATA}" = "true" ]; then
            echo "[REFRESH] cleaning outputs..."
            rm -f data/raw/prices.parquet data/raw/prices.csv data/raw/prices_meta.json || true
            rm -rf data/features data/labels || true
            rm -f data/raw_data.csv data/strategy_raw_data.csv || true
            rm -f app/model.pkl app/scaler.pkl app/tail_model.pkl app/tail_scaler.pkl || true
          else
            echo "[REFRESH] false (skip clean)"
          fi

      # Universe
      - name: Universe
        run: |
          python scripts/universe.py

      # Prices (없으면 생성)
      - name: Fetch prices (include market tickers) - if missing
        run: |
          if [ -f data/raw/prices.parquet ] || [ -f data/raw/prices.csv ]; then
            echo "[SKIP] prices already exist"
          else
            python scripts/fetch_prices.py --include-extra --force-full
          fi

      # Features (없으면 생성)
      - name: Build features - if missing
        run: |
          if [ -f data/features/features_model.parquet ] || [ -f data/features/features_model.csv ]; then
            echo "[SKIP] features_model already exists"
          else
            python scripts/build_features.py
          fi

      - name: Normalize features output (ensure features_model.*)
        run: |
          python - <<'PY'
          from pathlib import Path
          import pandas as pd

          feat_dir = Path("data/features")
          feat_dir.mkdir(parents=True, exist_ok=True)

          target_parq = feat_dir / "features_model.parquet"
          target_csv  = feat_dir / "features_model.csv"

          if target_parq.exists() or target_csv.exists():
            print("[SKIP] features_model already exists")
            raise SystemExit(0)

          candidates = []
          candidates += list(feat_dir.glob("*.parquet"))
          candidates += list(feat_dir.glob("*.csv"))
          candidates = [p for p in candidates if p.is_file()]

          if not candidates:
            raise FileNotFoundError(f"No feature files found in {feat_dir}. build_features.py output 확인 필요.")

          candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)

          chosen = None
          for p in candidates:
            try:
              df = pd.read_parquet(p) if p.suffix.lower()==".parquet" else pd.read_csv(p)
              if {"Date","Ticker"}.issubset(df.columns):
                chosen = (p, df)
                break
            except Exception as e:
              print("[WARN] cannot read", p, e)

          if chosen is None:
            raise RuntimeError("No usable feature file (need Date/Ticker columns).")

          p, df = chosen
          print("[INFO] chosen features file:", p)

          # write canonical
          try:
            df.to_parquet(target_parq, index=False)
            print("[DONE] wrote", target_parq)
          except Exception as e:
            print("[WARN] parquet write failed:", e, "-> writing csv")
            df.to_csv(target_csv, index=False)
            print("[DONE] wrote", target_csv)
          PY


      # Labels (Success) -> data/raw_data.csv
      - name: Build labels (Success) - if missing for TAG
        run: |
          mkdir -p data/labels
          if ls data/labels 2>/dev/null | grep -q "raw_data_${TAG}"; then
            echo "[SKIP] raw_data_${TAG} exists"
          else
            python scripts/build_labels.py \
              --profit-target "${PROFIT_TARGET}" \
              --max-days "${HOLDING_DAYS}" \
              --stop-level "${STOP_LEVEL}" \
              --max-extend-days "${MAX_EXTEND_DAYS}"
          fi

      # Train success model -> app/model.pkl, app/scaler.pkl
      - name: Train success model - ensure app/model.pkl & app/scaler.pkl
        run: |
          set -euo pipefail
          mkdir -p app

          if [ -f app/model.pkl ] && [ -f app/scaler.pkl ]; then
            echo "[SKIP] success model already exists"
          else
            python scripts/train_model.py
          fi

          echo "=== app/ ==="
          ls -la app || true

          if [ ! -f app/model.pkl ] || [ ! -f app/scaler.pkl ]; then
            echo "[ERROR] Missing app/model.pkl or app/scaler.pkl after training"
            exit 1
          fi

      # Strategy labels (Tail 등) -> data/strategy_raw_data.csv
      - name: Build strategy labels (Tail) - if missing for TAG
        run: |
          mkdir -p data/labels
          if ls data/labels 2>/dev/null | grep -q "strategy_raw_data_${TAG}"; then
            echo "[SKIP] strategy_raw_data_${TAG} exists"
          else
            python scripts/build_strategy_labels.py \
              --profit-target "${PROFIT_TARGET}" \
              --max-days "${HOLDING_DAYS}" \
              --stop-level "${STOP_LEVEL}" \
              --max-extend-days "${MAX_EXTEND_DAYS}"
          fi

      # Train tail model -> app/tail_model.pkl, app/tail_scaler.pkl
      - name: Train tail model - ensure app/tail_model.pkl & app/tail_scaler.pkl
        run: |
          set -euo pipefail
          mkdir -p app

          if [ -f app/tail_model.pkl ] && [ -f app/tail_scaler.pkl ]; then
            echo "[SKIP] tail model already exists"
          else
            python scripts/train_strategy_models.py \
              --profit-target "${PROFIT_TARGET}" \
              --max-days "${HOLDING_DAYS}" \
              --stop-level "${STOP_LEVEL}" \
              --max-extend-days "${MAX_EXTEND_DAYS}"
          fi

          echo "=== app/ ==="
          ls -la app || true

          if [ ! -f app/tail_model.pkl ] || [ ! -f app/tail_scaler.pkl ]; then
            echo "[WARN] tail model missing -> tail gates will be skipped"
            echo "TAIL_OK=0" >> $GITHUB_ENV
          else
            echo "TAIL_OK=1" >> $GITHUB_ENV
          fi

      - name: Gate grid runs (none / tail / utility / tail_utility) x (lists)
        shell: bash
        run: |
          set -euo pipefail

          # ✅ 항상 워크스페이스 루트로 이동
          cd "${GITHUB_WORKSPACE}"
          echo "PWD=$(pwd)"
          echo "=== top ==="
          ls -la || true
          echo "=== scripts ==="
          ls -la scripts || true

          echo "=== find predict_gate / simulate engine ==="
          PRED="$(find . -maxdepth 6 -type f \( -iname 'predict_gate.py' \) | head -n 1 || true)"
          SIM="$(find . -maxdepth 6 -type f \( -iname 'simulate_single_position_engine.py' \) | head -n 1 || true)"

          echo "[INFO] PRED candidate: ${PRED}"
          echo "[INFO] SIM  candidate: ${SIM}"

          if [ -z "${PRED}" ]; then
            echo "[ERROR] predict_gate.py not found anywhere under workspace."
            echo "Hint: file not committed OR different filename/case OR checked out under different path."
            echo "=== git ls-files grep predict_gate ==="
            git ls-files | grep -i "predict_gate.py" || true
            exit 1
          fi

          if [ -z "${SIM}" ]; then
            echo "[ERROR] simulate_single_position_engine.py not found anywhere under workspace."
            echo "=== git ls-files grep simulate_single_position_engine ==="
            git ls-files | grep -i "simulate_single_position_engine.py" || true
            exit 1
          fi

          # ./로 시작해도 python이 잘 받음
          echo "[INFO] using PRED=${PRED}"
          echo "[INFO] using SIM=${SIM}"

          PT="${PROFIT_TARGET}"
          H="${HOLDING_DAYS}"
          SL="${STOP_LEVEL}"
          EX="${MAX_EXTEND_DAYS}"
          LAM="${LAMBDA_TAIL}"

          IFS=',' read -ra TAILS <<< "${TAIL_MAX_LIST}"
          IFS=',' read -ra UQS   <<< "${U_QUANTILE_LIST}"
          IFS=',' read -ra RANKS <<< "${RANK_BY_LIST}"

          trim () { echo "$1" | xargs; }
          safe () { echo "$1" | sed 's/\./p/g' | sed 's/-/m/g'; }

          run_one () {
            local MODE="$1"
            local TMAX="$2"
            local UQ="$3"
            local RANK="$4"

            local TMAX_T="$(safe "$(trim "$TMAX")")"
            local UQ_T="$(safe "$(trim "$UQ")")"
            local RANK_T="$(trim "$RANK")"

            local SUFFIX="${MODE}_t${TMAX_T}_q${UQ_T}_r${RANK_T}"

            echo ""
            echo "=============================="
            echo "[RUN] mode=${MODE} tail_max=${TMAX} u_q=${UQ} rank_by=${RANK} suffix=${SUFFIX}"
            echo "=============================="

            python "${PRED}" \
              --profit-target "${PT}" \
              --max-days "${H}" \
              --stop-level "${SL}" \
              --max-extend-days "${EX}" \
              --gate-mode "${MODE}" \
              --tail-max "$(trim "$TMAX")" \
              --u-quantile "$(trim "$UQ")" \
              --rank-by "${RANK_T}" \
              --lambda-tail "${LAM}" \
              --out-suffix "${SUFFIX}"

            python "${SIM}" \
              --profit-target "${PT}" \
              --max-days "${H}" \
              --stop-level "${SL}" \
              --max-extend-days "${EX}" \
              --method custom \
              --pick-col pick_custom \
              --picks-path "data/signals/picks_${TAG}_gate_${SUFFIX}.csv" \
              --label "${SUFFIX}" \
              --out-suffix "${SUFFIX}" \
              --initial-seed 40000000
          }

          BASE_T="${TAILS[0]}"
          BASE_Q="${UQS[0]}"

          # 1) baseline: no gate
          for R in "${RANKS[@]}"; do
            run_one "none" "${BASE_T}" "${BASE_Q}" "${R}"
          done

          # 2) tail gate (tail model 있을 때만)
          if [ "${TAIL_OK:-0}" = "1" ]; then
            for T in "${TAILS[@]}"; do
              for R in "${RANKS[@]}"; do
                run_one "tail" "${T}" "${BASE_Q}" "${R}"
              done
            done
          else
            echo "[SKIP] tail gates skipped (TAIL_OK=0)"
          fi

          # 3) utility gate
          for Q in "${UQS[@]}"; do
            for R in "${RANKS[@]}"; do
              run_one "utility" "${BASE_T}" "${Q}" "${R}"
            done
          done

          # 4) tail + utility gate (tail model 있을 때만)
          if [ "${TAIL_OK:-0}" = "1" ]; then
            for T in "${TAILS[@]}"; do
              for Q in "${UQS[@]}"; do
                for R in "${RANKS[@]}"; do
                  run_one "tail_utility" "${T}" "${Q}" "${R}"
                done
              done
            done
          else
            echo "[SKIP] tail_utility gates skipped (TAIL_OK=0)"
          fi

      - name: Merge gate summaries (optional)
        run: |
          if [ -f scripts/merge_gate_summaries.py ]; then
            python scripts/merge_gate_summaries.py --tag "${TAG}"
          else
            echo "[WARN] scripts/merge_gate_summaries.py not found (skip merge)"
          fi

      - name: Build gate summary CSV (recent10y + maxextend + cycles + success)
        shell: bash
        run: |
          set -euo pipefail
          cd "${GITHUB_WORKSPACE}"

          # pyarrow가 없으면 parquet 읽기에서 죽을 수 있어서 안전하게 보장
          python - <<'PY'
          import importlib, sys
          try:
            importlib.import_module("pyarrow")
            print("[OK] pyarrow exists")
          except Exception:
            print("[WARN] pyarrow missing -> installing")
            sys.exit(1)
          PY
        continue-on-error: true

      - name: Ensure pyarrow (if missing)
        if: ${{ failure() }}
        run: |
          pip install -U pyarrow

      - name: Make gate summary csv
        shell: bash
        run: |
          set -euo pipefail
          cd "${GITHUB_WORKSPACE}"

          python scripts/make_gate_summary.py \
            --tag "${TAG}" \
            --max-days "${HOLDING_DAYS}" \
            --recent-years 10

          echo "=== produced files ==="
          ls -la data/signals | tail -n 200

      - name: Upload gate artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gate-results-${{ env.TAG }}
          retention-days: 14
          if-no-files-found: error
          path: |
            data/signals/gate_summary_${{ env.TAG }}.csv
            data/signals/sim_engine_summary_${{ env.TAG }}_GATES_ALL.csv
            data/signals/picks_${{ env.TAG }}_gate_*.csv
            data/signals/sim_engine_trade_log_${{ env.TAG }}_*.csv
            data/signals/sim_engine_curve_${{ env.TAG }}_*.parquet


      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: gate-results
          path: |
            data/signals/**
            data/features/**
            data/labels/**
            data/raw/**
            data/raw_data.csv
            data/strategy_raw_data.csv
            app/**
