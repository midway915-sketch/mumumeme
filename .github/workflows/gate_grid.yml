name: gate-grid

on:
  workflow_dispatch:
    inputs:
      profit_target:
        description: "profit target (e.g. 0.10)"
        required: true
        default: "0.10"
      max_days:
        description: "max holding days (e.g. 40)"
        required: true
        default: "40"
      stop_level:
        description: "stop level (e.g. -0.10)"
        required: true
        default: "-0.10"
      max_extend_days:
        description: "extend horizon tag + strategy label horizon add (e.g. 30)"
        required: true
        default: "30"

      # Gate grids
      p_tail_thresholds:
        description: "comma-separated p_tail thresholds (e.g. 0.10,0.20,0.30)"
        required: true
        default: "0.10,0.20,0.30"
      utility_quantiles:
        description: "comma-separated utility quantiles (e.g. 0.60,0.75,0.90)"
        required: true
        default: "0.60,0.75,0.90"
      rank_metrics:
        description: "comma-separated rank metric (utility|ret_score|p_success)"
        required: true
        default: "utility,ret_score"
      lambda_tail:
        description: "utility tail penalty lambda (single float, e.g. 0.05)"
        required: true
        default: "0.05"

      # ✅ NEW: ps_min grid
      ps_min_thresholds:
        description: "comma-separated p_success minimum thresholds (e.g. 0.00,0.05,0.10)"
        required: true
        default: "0.00,0.05,0.10"

      # Exit/portfolio grids (수익률 우선 추천 기본값)
      enable_trailing:
        description: "true to enable 2-step exit (TP1 + trailing stop)"
        required: true
        default: "true"
      tp1_frac:
        description: "fraction to sell at profit target (e.g. 0.50)"
        required: true
        default: "0.50"
      trail_stops:
        description: "comma-separated trailing stops (e.g. 0.08,0.10,0.12)"
        required: true
        default: "0.08,0.10,0.12"

      topk_configs:
        description: "TopK configs: '1|1.0;2|0.7,0.3;2|0.6,0.4'"
        required: true
        default: "1|1.0;2|0.7,0.3;2|0.6,0.4"

      exclude_tickers:
        description: "comma-separated tickers to exclude (e.g. SPY,^VIX)"
        required: true
        default: "SPY,^VIX"

      rebuild_all:
        description: "true to rebuild prices/features/labels/models from scratch"
        required: true
        default: "false"

  schedule:
    # 매일 한국시간 08:10 (UTC 23:10)
    - cron: "10 23 * * *"

jobs:
  grid:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas numpy yfinance pyarrow scikit-learn joblib
          fi

      - name: Ensure folders
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/raw data/features data/labels data/signals data/meta data/_backup app scripts

      - name: Set label env (LABEL_SPEC + LABEL_KEY)
        shell: bash
        run: |
          set -euo pipefail
          echo "LABEL_SPEC=pt=${{ inputs.profit_target }},h=${{ inputs.max_days }},sl=${{ inputs.stop_level }},ex=${{ inputs.max_extend_days }}" >> $GITHUB_ENV
          echo "LABEL_KEY=pt${{ inputs.profit_target }}_h${{ inputs.max_days }}_sl${{ inputs.stop_level }}_ex${{ inputs.max_extend_days }}" \
            | sed 's/\.//g; s/-//g' \
            >> $GITHUB_ENV

      # ---- PRICES cache
      - name: Restore cache (PRICES)
        uses: actions/cache@v4
        with:
          path: |
            data/raw/prices.parquet
            data/raw/prices.csv
            data/raw/prices_meta.json
          key: mumumeme-prices-v2-${{ runner.os }}-${{ hashFiles('data/universe.csv','scripts/universe.py','scripts/fetch_prices.py') }}
          restore-keys: |
            mumumeme-prices-v2-${{ runner.os }}-

      # ---- FEATURES cache
      - name: Restore cache (FEATURES_MODEL)
        uses: actions/cache@v4
        with:
          path: |
            data/features/features_model.parquet
            data/features/features_model.csv
          key: mumumeme-features-v2-${{ runner.os }}-${{ hashFiles('data/universe.csv','scripts/universe.py','scripts/fetch_prices.py','scripts/build_features.py') }}
          restore-keys: |
            mumumeme-features-v2-${{ runner.os }}-

      # ---- MODEL cache (쉼표 없는 LABEL_KEY 사용)
      - name: Restore cache (MODEL)
        uses: actions/cache@v4
        with:
          path: |
            data/labels/labels_model.parquet
            data/labels/labels_model.csv
            app/model.pkl
            app/scaler.pkl
            data/meta/build_fingerprint.json
          key: mumumeme-model-v2-${{ runner.os }}-${{ env.LABEL_KEY }}-${{ hashFiles('scripts/build_labels.py','scripts/train_model.py','scripts/check_rebuild.py','scripts/merge_incremental_table.py') }}
          restore-keys: |
            mumumeme-model-v2-${{ runner.os }}-${{ env.LABEL_KEY }}-
            mumumeme-model-v2-${{ runner.os }}-

      - name: Fingerprint check (partial rebuild flags)
        shell: bash
        run: |
          set -euo pipefail
          out="$(python scripts/check_rebuild.py \
            --fingerprint-path data/meta/build_fingerprint.json \
            --label-spec "${{ env.LABEL_SPEC }}" \
            --features-files "scripts/build_features.py" \
            --labels-files "scripts/build_labels.py,scripts/train_model.py" \
            --universe-files "scripts/universe.py,data/universe.csv" \
            --strategy-files "scripts/predict_gate.py,scripts/simulate_single_position_engine.py,scripts/run_grid_workflow.sh" \
          )"
          echo "$out"
          # check_rebuild.py가 마지막 4줄을 KEY=VALUE 형태로 내보낸다는 전제
          echo "$out" | tail -n 4 >> $GITHUB_ENV

      - name: Prepare required files (daily incremental)
        shell: bash
        env:
          REBUILD_ALL: ${{ inputs.rebuild_all }}
          REBUILD_PRICES: ${{ env.REBUILD_PRICES }}
          REBUILD_FEATURES: ${{ env.REBUILD_FEATURES }}
          REBUILD_MODEL: ${{ env.REBUILD_MODEL }}
          CLEAR_SIGNALS: ${{ env.CLEAR_SIGNALS }}

          PROFIT_TARGET: ${{ inputs.profit_target }}
          MAX_DAYS: ${{ inputs.max_days }}
          STOP_LEVEL: ${{ inputs.stop_level }}
          MAX_EXTEND_DAYS: ${{ inputs.max_extend_days }}
        run: |
          set -euo pipefail

          if [ "$REBUILD_ALL" = "true" ]; then
            REBUILD_PRICES="1"; REBUILD_FEATURES="1"; REBUILD_MODEL="1"; CLEAR_SIGNALS="1"
          fi

          if [ "${CLEAR_SIGNALS:-0}" = "1" ]; then
            rm -rf data/signals/* || true
          fi

          # upstream 삭제
          if [ "${REBUILD_PRICES:-0}" = "1" ]; then
            rm -f data/raw/prices.parquet data/raw/prices.csv data/raw/prices_meta.json || true
            rm -f data/features/features_model.parquet data/features/features_model.csv || true
            rm -f data/labels/labels_model.parquet data/labels/labels_model.csv || true
            rm -f app/model.pkl app/scaler.pkl || true
          elif [ "${REBUILD_FEATURES:-0}" = "1" ]; then
            rm -f data/features/features_model.parquet data/features/features_model.csv || true
            rm -f data/labels/labels_model.parquet data/labels/labels_model.csv || true
            rm -f app/model.pkl app/scaler.pkl || true
          elif [ "${REBUILD_MODEL:-0}" = "1" ]; then
            rm -f data/labels/labels_model.parquet data/labels/labels_model.csv || true
            rm -f app/model.pkl app/scaler.pkl || true
          fi

          # 1) prices
          python scripts/universe.py
          if [ ! -f data/raw/prices.parquet ] && [ ! -f data/raw/prices.csv ]; then
            python scripts/fetch_prices.py --include-extra --reset --force-full
          else
            python scripts/fetch_prices.py --include-extra --lookback-days 10
          fi

          # 2) features (없으면 full)
          if [ ! -f data/features/features_model.parquet ] && [ ! -f data/features/features_model.csv ]; then
            python scripts/build_features.py
          else
            echo "[INFO] features_model exists -> reuse"
          fi

          # 3) labels + model (없으면 생성)
          if [ ! -f data/labels/labels_model.parquet ] && [ ! -f data/labels/labels_model.csv ]; then
            python scripts/build_labels.py \
              --profit-target "$PROFIT_TARGET" \
              --max-days "$MAX_DAYS" \
              --stop-level "$STOP_LEVEL"
          else
            echo "[INFO] labels_model exists -> reuse"
          fi

          if [ ! -f app/model.pkl ] || [ ! -f app/scaler.pkl ]; then
            python scripts/train_model.py
          else
            echo "[INFO] model exists -> reuse"
          fi

      - name: Run gate grid (predict + simulate + summarize)
        shell: bash
        env:
          LABEL_KEY: ${{ env.LABEL_KEY }}

          PROFIT_TARGET: ${{ inputs.profit_target }}
          MAX_DAYS: ${{ inputs.max_days }}
          STOP_LEVEL: ${{ inputs.stop_level }}
          MAX_EXTEND_DAYS: ${{ inputs.max_extend_days }}

          P_TAIL_THRESHOLDS: ${{ inputs.p_tail_thresholds }}
          UTILITY_QUANTILES: ${{ inputs.utility_quantiles }}
          RANK_METRICS: ${{ inputs.rank_metrics }}
          LAMBDA_TAIL: ${{ inputs.lambda_tail }}

          # ✅ NEW: p_success min thresholds grid
          PS_MIN_THRESHOLDS: ${{ inputs.ps_min_thresholds }}

          # exits/topk
          ENABLE_TRAILING: ${{ inputs.enable_trailing }}
          TP1_FRAC: ${{ inputs.tp1_frac }}
          TRAIL_STOPS: ${{ inputs.trail_stops }}
          TOPK_CONFIGS: ${{ inputs.topk_configs }}

          OUT_DIR: data/signals
          EXCLUDE_TICKERS: ${{ inputs.exclude_tickers }}

          GATE_MODES: "none,tail,utility,tail_utility"

          REQUIRE_FILES: "data/features/features_model.parquet,app/model.pkl,app/scaler.pkl"
        run: |
          set -euo pipefail
          chmod +x scripts/run_grid_workflow.sh || true
          bash scripts/run_grid_workflow.sh

      - name: Aggregate summaries
        shell: bash
        run: |
          set -euo pipefail
          python scripts/aggregate_gate_grid.py \
            --signals-dir "data/signals" \
            --out-aggregate "data/signals/gate_grid_aggregate.csv" \
            --out-top "data/signals/gate_grid_top_by_recent10y.csv" \
            --pattern "gate_summary_*.csv" \
            --topn 30

      - name: Upload artifacts (signals + meta)
        uses: actions/upload-artifact@v4
        with:
          name: gate-grid-results
          path: |
            data/meta/build_fingerprint.json
            data/signals/picks_*.csv
            data/signals/picks_meta_*.json
            data/signals/gate_summary_*.csv
            data/signals/gate_grid_aggregate.csv
            data/signals/gate_grid_top_by_recent10y.csv
            data/signals/sim_engine_trades_*.parquet
            data/signals/sim_engine_curve_*.parquet
          if-no-files-found: error