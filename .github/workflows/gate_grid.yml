name: gate-grid

on:
  workflow_dispatch:
    inputs:
      profit_target:
        description: "profit target (e.g. 0.10)"
        required: true
        default: "0.10"
      max_days:
        description: "max holding days H (e.g. 40)"
        required: true
        default: "40"
      stop_level:
        description: "stop level (e.g. -0.10)"
        required: true
        default: "-0.10"

      p_tail_thresholds:
        description: "comma-separated p_tail thresholds (e.g. 0.10,0.20,0.30)"
        required: true
        default: "0.10,0.20,0.30"
      utility_quantiles:
        description: "comma-separated utility quantiles (e.g. 0.60,0.75,0.90)"
        required: true
        default: "0.60,0.75,0.90"
      ps_mins:
        description: "comma-separated p_success minimum cutoffs (e.g. 0.50,0.60,0.70)"
        required: true
        default: "0.00,0.50,0.60,0.70"
      rank_metrics:
        description: "comma-separated rank metric (utility|ret_score|p_success). e.g. utility,ret_score"
        required: true
        default: "utility,ret_score"
      lambda_tail:
        description: "utility tail penalty lambda (single float, e.g. 0.05)"
        required: true
        default: "0.05"

      rebuild_all:
        description: "true to rebuild prices/features/labels/models from scratch"
        required: true
        default: "false"

  schedule:
    # 매일 한국시간 08:10 (UTC 23:10)
    - cron: "10 23 * * *"

# ✅ 겹침 방지: 스케줄 돌고 있는데 수동 실행 들어오면 이전 실행 취소(원하면 false로 바꿔)
concurrency:
  group: gate-grid-${{ github.ref }}
  cancel-in-progress: true

jobs:
  grid:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read

    # ✅ schedule에서도 값이 항상 존재하도록 기본값 강제 + schedule는 자동 경량 프리셋 적용
    env:
      # --- core params
      PROFIT_TARGET: ${{ github.event.inputs.profit_target || '0.10' }}
      MAX_DAYS: ${{ github.event.inputs.max_days || '40' }}
      STOP_LEVEL: ${{ github.event.inputs.stop_level || '-0.10' }}

      # --- grid dims (schedule 프리셋)
      P_TAIL_THRESHOLDS: ${{ (github.event_name == 'schedule') && '0.20,0.30' || (github.event.inputs.p_tail_thresholds || '0.10,0.20,0.30') }}
      UTILITY_QUANTILES: ${{ (github.event_name == 'schedule') && '0.75,0.90' || (github.event.inputs.utility_quantiles || '0.60,0.75,0.90') }}
      PS_MINS: ${{ (github.event_name == 'schedule') && '0.50,0.60' || (github.event.inputs.ps_mins || '0.00,0.50,0.60,0.70') }}
      RANK_METRICS: ${{ (github.event_name == 'schedule') && 'utility' || (github.event.inputs.rank_metrics || 'utility,ret_score') }}
      LAMBDA_TAIL: ${{ github.event.inputs.lambda_tail || '0.05' }}

      # schedule은 모드도 축소(가장 “의미있는” 조합 위주)
      GATE_MODES: ${{ (github.event_name == 'schedule') && 'tail_utility,utility' || 'none,tail,utility,tail_utility' }}

      # trailing/topk도 축소
      TRAIL_STOPS: ${{ (github.event_name == 'schedule') && '0.10' || '0.08,0.10,0.12' }}
      TOPK_CONFIGS: ${{ (github.event_name == 'schedule') && '1|1.0;2|0.7,0.3' || '1|1.0;2|0.7,0.3;2|0.6,0.4' }}

      # rebuild
      REBUILD_ALL: ${{ github.event.inputs.rebuild_all || 'false' }}

      # misc
      PRICE_START: "2015-02-21"
      OUT_DIR: "data/signals"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas numpy yfinance pyarrow scikit-learn joblib
          fi

      - name: Ensure folders
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/raw data/features data/labels data/signals data/meta app scripts data/_backup

      - name: Set env keys (LABEL_KEY + MAX_EXTEND_DAYS auto)
        shell: bash
        run: |
          set -euo pipefail

          echo "LABEL_KEY=pt$(python - <<'PY'
          pt=float("${PROFIT_TARGET}")
          print(int(round(pt*100)))
          PY
          )_h${MAX_DAYS}_sl$(python - <<'PY'
          sl=float("${STOP_LEVEL}")
          print(int(round(abs(sl)*100)))
          PY
          )" >> $GITHUB_ENV

          echo "MAX_EXTEND_DAYS=$(python - <<'PY'
          H=int("${MAX_DAYS}")
          print(max(1, H//2))
          PY
          )" >> $GITHUB_ENV

      - name: Restore cache (PRICES)
        id: cache_prices
        uses: actions/cache@v4
        with:
          path: |
            data/raw/prices.parquet
            data/raw/prices.csv
            data/raw/prices_meta.json
          key: mumumeme-prices-v3-${{ runner.os }}-${{ hashFiles('data/universe.csv','scripts/universe.py','scripts/fetch_prices.py') }}
          restore-keys: |
            mumumeme-prices-v3-${{ runner.os }}-

      - name: Restore cache (FEATURES_MODEL)
        id: cache_features
        uses: actions/cache@v4
        with:
          path: |
            data/features/features_model.parquet
            data/features/features_model.csv
            data/meta/feature_cols.json
          key: mumumeme-features-v3-${{ runner.os }}-${{ hashFiles('data/universe.csv','scripts/universe.py','scripts/fetch_prices.py','scripts/build_features.py','scripts/feature_spec.py') }}
          restore-keys: |
            mumumeme-features-v3-${{ runner.os }}-

      - name: Restore cache (MODEL)
        id: cache_model
        uses: actions/cache@v4
        with:
          path: |
            data/labels/labels_model.parquet
            data/labels/labels_model.csv
            app/model.pkl
            app/scaler.pkl
            data/meta/train_model_report*.json
          key: mumumeme-model-v3-${{ runner.os }}-${{ env.LABEL_KEY }}-${{ hashFiles('scripts/build_labels.py','scripts/train_model.py') }}
          restore-keys: |
            mumumeme-model-v3-${{ runner.os }}-${{ env.LABEL_KEY }}-
            mumumeme-model-v3-${{ runner.os }}-

      - name: Restore cache (TAIL)
        id: cache_tail
        uses: actions/cache@v4
        with:
          path: |
            data/labels/labels_tail_*.parquet
            data/labels/labels_tail_*.csv
            data/labels/labels_tail_*_meta.json
            app/tail_model.pkl
            app/tail_scaler.pkl
            data/meta/train_tail_report_*.json
          key: mumumeme-tail-v3-${{ runner.os }}-${{ env.LABEL_KEY }}-ex${{ env.MAX_EXTEND_DAYS }}-${{ hashFiles('scripts/build_tail_labels.py','scripts/train_tail_model.py') }}
          restore-keys: |
            mumumeme-tail-v3-${{ runner.os }}-${{ env.LABEL_KEY }}-ex${{ env.MAX_EXTEND_DAYS }}-
            mumumeme-tail-v3-${{ runner.os }}-${{ env.LABEL_KEY }}-
            mumumeme-tail-v3-${{ runner.os }}-

      - name: Restore cache (TAU)
        id: cache_tau
        uses: actions/cache@v4
        with:
          path: |
            data/labels/labels_tau.parquet
            data/labels/labels_tau.csv
            app/tau_model.pkl
            app/tau_scaler.pkl
            data/meta/train_tau_report*.json
          key: mumumeme-tau-v3-${{ runner.os }}-${{ hashFiles('scripts/build_tau_labels.py','scripts/train_tau_model.py') }}
          restore-keys: |
            mumumeme-tau-v3-${{ runner.os }}-

      - name: Prepare required files (10y only + partial rebuild)
        shell: bash
        env:
          REBUILD_ALL: ${{ env.REBUILD_ALL }}
          PRICE_START: ${{ env.PRICE_START }}

          PROFIT_TARGET: ${{ env.PROFIT_TARGET }}
          MAX_DAYS: ${{ env.MAX_DAYS }}
          STOP_LEVEL: ${{ env.STOP_LEVEL }}
          MAX_EXTEND_DAYS: ${{ env.MAX_EXTEND_DAYS }}

          LABEL_KEY: ${{ env.LABEL_KEY }}
        run: |
          set -euo pipefail

          if [ "$REBUILD_ALL" = "true" ]; then
            rm -rf data/raw/* data/features/* data/labels/* app/* data/signals/* data/meta/* || true
          fi

          # 1) universe + prices (10y만)
          python scripts/universe.py
          if [ ! -f data/raw/prices.parquet ] && [ ! -f data/raw/prices.csv ]; then
            python scripts/fetch_prices.py --include-extra --reset --force-full --start "$PRICE_START"
          else
            python scripts/fetch_prices.py --include-extra --lookback-days 10 --start "$PRICE_START"
          fi

          # 2) features
          # ✅ SSOT(meta/feature_cols.json)가 없으면 features를 재생성해서 SSOT를 반드시 만든다.
          if [ ! -f data/meta/feature_cols.json ]; then
            echo "[WARN] SSOT feature_cols.json missing -> rebuild features_model to restore SSOT"
            rm -f data/features/features_model.parquet data/features/features_model.csv || true
          fi

          if [ ! -f data/features/features_model.parquet ] && [ ! -f data/features/features_model.csv ]; then
            python scripts/build_features.py
          else
            echo "[INFO] features_model exists -> reuse"
          fi

          # 3) labels (p_success 학습 데이터)
          if [ ! -f data/labels/labels_model.parquet ] && [ ! -f data/labels/labels_model.csv ]; then
            python scripts/build_labels.py \
              --profit-target "$PROFIT_TARGET" \
              --max-days "$MAX_DAYS" \
              --stop-level "$STOP_LEVEL"
          else
            echo "[INFO] labels_model exists -> reuse"
          fi

          # 4) p_success model.pkl / scaler.pkl
          if [ ! -f app/model.pkl ] || [ ! -f app/scaler.pkl ]; then
            python scripts/train_model.py
          else
            echo "[INFO] p_success model exists -> reuse"
          fi

          # 4b) labels_tail_{EX_TAG}
          EX_TAG="pt$(python - <<PY
          pt=float("$PROFIT_TARGET")
          print(int(round(pt*100)))
          PY
          )_h${MAX_DAYS}_sl$(python - <<PY
          sl=float("$STOP_LEVEL")
          print(int(round(abs(sl)*100)))
          PY
          )_ex${MAX_EXTEND_DAYS}"

          if [ ! -f "data/labels/labels_tail_${EX_TAG}.parquet" ] && [ ! -f "data/labels/labels_tail_${EX_TAG}.csv" ]; then
            python scripts/build_tail_labels.py \
              --profit-target "$PROFIT_TARGET" \
              --max-days "$MAX_DAYS" \
              --stop-level "$STOP_LEVEL" \
              --max-extend-days "$MAX_EXTEND_DAYS"
          else
            echo "[INFO] labels_tail exists -> reuse"
          fi

          # 4c) tail_model.pkl / tail_scaler.pkl
          if [ ! -f app/tail_model.pkl ] || [ ! -f app/tail_scaler.pkl ]; then
            python scripts/train_tail_model.py \
              --profit-target "$PROFIT_TARGET" \
              --max-days "$MAX_DAYS" \
              --stop-level "$STOP_LEVEL" \
              --max-extend-days "$MAX_EXTEND_DAYS"
          else
            echo "[INFO] tail model exists -> reuse"
          fi

          # 4d) TAU labels + model (있으면 사용)
          if [ -f scripts/build_tau_labels.py ]; then
            if [ ! -f data/labels/labels_tau.parquet ] && [ ! -f data/labels/labels_tau.csv ]; then
              python scripts/build_tau_labels.py \
                --profit-target "$PROFIT_TARGET" \
                --max-days "$MAX_DAYS" \
                --stop-level "$STOP_LEVEL" \
                --max-extend-days "$MAX_EXTEND_DAYS"
            else
              echo "[INFO] labels_tau exists -> reuse"
            fi
          else
            echo "[WARN] scripts/build_tau_labels.py not found -> skip tau labels"
          fi

          if [ -f scripts/train_tau_model.py ] && ([ -f data/labels/labels_tau.parquet ] || [ -f data/labels/labels_tau.csv ]); then
            if [ ! -f app/tau_model.pkl ] || [ ! -f app/tau_scaler.pkl ]; then
              python scripts/train_tau_model.py \
                --profit-target "$PROFIT_TARGET" \
                --max-days "$MAX_DAYS" \
                --stop-level "$STOP_LEVEL" \
                --max-extend-days "$MAX_EXTEND_DAYS" || \
              python scripts/train_tau_model.py
            else
              echo "[INFO] tau model exists -> reuse"
            fi
          else
            echo "[WARN] tau training skipped (missing script or labels_tau)"
          fi

          # 5) score features (항상 실행)
          python scripts/score_features.py --tag "$LABEL_KEY"

      - name: Run gate grid (predict + simulate + summarize)
        shell: bash
        env:
          LABEL_KEY: ${{ env.LABEL_KEY }}

          PROFIT_TARGET: ${{ env.PROFIT_TARGET }}
          MAX_DAYS: ${{ env.MAX_DAYS }}
          STOP_LEVEL: ${{ env.STOP_LEVEL }}
          MAX_EXTEND_DAYS: ${{ env.MAX_EXTEND_DAYS }}

          P_TAIL_THRESHOLDS: ${{ env.P_TAIL_THRESHOLDS }}
          UTILITY_QUANTILES: ${{ env.UTILITY_QUANTILES }}
          RANK_METRICS: ${{ env.RANK_METRICS }}
          LAMBDA_TAIL: ${{ env.LAMBDA_TAIL }}

          GATE_MODES: ${{ env.GATE_MODES }}

          ENABLE_TRAILING: "true"
          TP1_FRAC: "0.50"
          TRAIL_STOPS: ${{ env.TRAIL_STOPS }}

          TOPK_CONFIGS: ${{ env.TOPK_CONFIGS }}
          PS_MINS: ${{ env.PS_MINS }}

          MAX_LEVERAGE_PCT: "1.00"

          OUT_DIR: "data/signals"
          EXCLUDE_TICKERS: "SPY,^VIX"
          REQUIRE_FILES: "data/features/features_scored.parquet,app/model.pkl,app/scaler.pkl"
        run: |
          set -euo pipefail
          chmod +x scripts/run_grid_workflow.sh
          bash scripts/run_grid_workflow.sh

      - name: Aggregate summaries
        shell: bash
        run: |
          set -euo pipefail
          python scripts/aggregate_gate_grid.py \
            --signals-dir "data/signals" \
            --out-aggregate "data/signals/gate_grid_aggregate.csv" \
            --out-top "data/signals/gate_grid_top_by_recent10y.csv" \
            --pattern "gate_summary_*.csv" \
            --topn 50

      - name: Write GitHub Step Summary (BEST + Top5)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import pandas as pd
          from pathlib import Path

          agg = Path("data/signals/gate_grid_aggregate.csv")
          top = Path("data/signals/gate_grid_top_by_recent10y.csv")

          lines = []
          lines.append("# gate-grid 결과 요약")
          lines.append("")

          if agg.exists():
            df = pd.read_csv(agg)
            if len(df):
              b = df.iloc[0].to_dict()
              lines.append("## BEST (SeedMultiple / LevAdj / CAGR 기준)")
              lines.append(f"- TAG: `{b.get('TAG')}`")
              lines.append(f"- Suffix: `{b.get('GateSuffix')}`")
              lines.append(f"- SeedMultiple: `{b.get('SeedMultiple')}`")
              if 'SeedMultiple_LevAdj' in b: lines.append(f"- SeedMultiple_LevAdj: `{b.get('SeedMultiple_LevAdj')}`")
              lines.append(f"- Recent10Y_SeedMultiple: `{b.get('Recent10Y_SeedMultiple')}`")
              lines.append(f"- CAGR_AfterWarmup: `{b.get('CAGR_AfterWarmup')}` (QQQ `{b.get('QQQ_CAGR_SamePeriod')}`)")
              lines.append(f"- IdlePctAfterWarmup: `{b.get('IdlePctAfterWarmup')}` / MaxLevPct `{b.get('MaxLeveragePct')}`")
              lines.append("")

          if top.exists():
            df = pd.read_csv(top)
            if len(df):
              show = df.head(5).copy()
              cols = [c for c in [
                "TAG","GateSuffix","Recent10Y_SeedMultiple","SeedMultiple","SeedMultiple_LevAdj",
                "CAGR_AfterWarmup","QQQ_CAGR_SamePeriod","IdlePctAfterWarmup","MaxLeveragePct","CycleCount","SuccessRate"
              ] if c in show.columns]
              show = show[cols]
              lines.append("## Top 5 (Recent10Y_SeedMultiple 기준)")
              lines.append("")
              lines.append(show.to_markdown(index=False))
              lines.append("")

          Path(".").joinpath("GITHUB_STEP_SUMMARY.txt")

          out = "\n".join(lines).strip() + "\n"
          # GitHub Actions provides the path via env var
          import os
          p = os.environ.get("GITHUB_STEP_SUMMARY")
          if p:
            Path(p).write_text(out, encoding="utf-8")
          else:
            print(out)
          PY

      - name: Upload artifacts (signals)
        uses: actions/upload-artifact@v4
        with:
          name: gate-grid-results
          path: |
            data/signals/gate_summary_*.csv
            data/signals/gate_grid_aggregate.csv
            data/signals/gate_grid_top_by_recent10y.csv
            data/signals/picks_*.csv
            data/signals/picks_meta_*.json
            data/signals/sim_engine_trades_*.parquet
            data/signals/sim_engine_curve_*.parquet
          if-no-files-found: error