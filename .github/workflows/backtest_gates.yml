name: backtest-gates

on:
  workflow_dispatch:
    inputs:
      PROFIT_TARGET:
        description: "profit target (e.g. 0.10)"
        required: true
        default: "0.10"
      HOLDING_DAYS:
        description: "max holding days (e.g. 40)"
        required: true
        default: "40"
      STOP_LEVEL:
        description: "stop level (e.g. -0.10)"
        required: true
        default: "-0.10"
      MAX_EXTEND_DAYS:
        description: "tag only (ex: 30)"
        required: true
        default: "30"

      # ✅ 여러 값 실험(콤마로 구분)
      TAIL_MAX_LIST:
        description: "comma-separated tail thresholds (e.g. 0.15,0.25,0.35)"
        required: true
        default: "0.20,0.30"
      U_QUANTILE_LIST:
        description: "comma-separated utility quantiles (e.g. 0.60,0.75,0.90)"
        required: true
        default: "0.75,0.90"
      RANK_BY_LIST:
        description: "comma-separated rank metric (utility|ret_score|p_success). e.g. utility,ret_score"
        required: true
        default: "utility"

      LAMBDA_TAIL:
        description: "utility tail penalty lambda (e.g. 0.05)"
        required: true
        default: "0.05"

      # ✅ 캐시 무시하고 강제 재생성
      REFRESH_DATA:
        description: "true to rebuild prices/features/labels/models from scratch"
        required: true
        default: "false"

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      PROFIT_TARGET: ${{ inputs.PROFIT_TARGET }}
      HOLDING_DAYS: ${{ inputs.HOLDING_DAYS }}
      STOP_LEVEL: ${{ inputs.STOP_LEVEL }}
      MAX_EXTEND_DAYS: ${{ inputs.MAX_EXTEND_DAYS }}

      TAIL_MAX_LIST: ${{ inputs.TAIL_MAX_LIST }}
      U_QUANTILE_LIST: ${{ inputs.U_QUANTILE_LIST }}
      RANK_BY_LIST: ${{ inputs.RANK_BY_LIST }}
      LAMBDA_TAIL: ${{ inputs.LAMBDA_TAIL }}

      REFRESH_DATA: ${{ inputs.REFRESH_DATA }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-py311-v1

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install numpy pandas scikit-learn joblib yfinance pyarrow

      # ✅ TAG 먼저 계산(파라미터 캐시 키로 사용)
      - name: Compute TAG
        run: |
          python - <<PY
          pt=float("${PROFIT_TARGET}")
          h=int("${HOLDING_DAYS}")
          sl=float("${STOP_LEVEL}")
          ex=int("${MAX_EXTEND_DAYS}")
          pt_tag=int(round(pt*100))
          sl_tag=int(round(abs(sl)*100))
          tag=f"pt{pt_tag}_h{h}_sl{sl_tag}_ex{ex}"
          with open("${GITHUB_ENV}","a",encoding="utf-8") as f:
              f.write("TAG="+tag+"\\n")
          print("TAG="+tag)
          PY

      # ---- universe 생성(가벼우니 항상)
      - name: Universe
        run: |
          python scripts/universe.py

      # ✅ 정적 캐시: prices + features
      - name: Cache static data (prices/features)
        uses: actions/cache@v4
        with:
          path: |
            data/raw/prices.parquet
            data/raw/prices.csv
            data/raw/prices_meta.json
            data/features/**
          key: static-${{ runner.os }}-${{ hashFiles('scripts/fetch_prices.py','scripts/build_features.py','scripts/universe.py','data/universe.csv') }}-v2
          restore-keys: |
            static-${{ runner.os }}-

      # ✅ 파라미터 캐시: labels + models (TAG에 종속)
      - name: Cache param data (labels/models by TAG)
        uses: actions/cache@v4
        with:
          path: |
            data/labels/**
            app/model.pkl
            app/scaler.pkl
            app/tail_model.pkl
            app/tail_scaler.pkl
          key: param-${{ runner.os }}-${{ env.TAG }}-${{ hashFiles('scripts/build_labels.py','scripts/build_strategy_labels.py','scripts/train_model.py','scripts/train_strategy_models.py') }}-v2
          restore-keys: |
            param-${{ runner.os }}-${{ env.TAG }}-

      # ✅ 필요하면 강제 클린(REFRESH_DATA=true)
      - name: Optional clean (refresh)
        run: |
          if [ "${REFRESH_DATA}" = "true" ]; then
            echo "[REFRESH] cleaning cached outputs..."
            rm -f data/raw/prices.parquet data/raw/prices.csv data/raw/prices_meta.json || true
            rm -rf data/features data/labels || true
            rm -f app/model.pkl app/scaler.pkl app/tail_model.pkl app/tail_scaler.pkl || true
          else
            echo "[REFRESH] false (skip clean)"
          fi

      # ---- prices: 있으면 스킵
      - name: Fetch prices (include market tickers) - if missing
        run: |
          if [ -f data/raw/prices.parquet ] || [ -f data/raw/prices.csv ]; then
            echo "[SKIP] prices already exist"
          else
            python scripts/fetch_prices.py --include-extra --force-full
          fi

      # ---- features: 있으면 스킵
      - name: Build features - if missing
        run: |
          if [ -f data/features/features_model.parquet ] || [ -f data/features/features_model.csv ]; then
            echo "[SKIP] features_model already exists"
          else
            python scripts/build_features.py
          fi

      # ---- labels: TAG 포함 파일이 있으면 스킵(파일명 몰라도 동작하도록 grep 방식)
      - name: Build labels - if missing for TAG
        run: |
          mkdir -p data/labels
          if ls data/labels 2>/dev/null | grep -q "${TAG}"; then
            echo "[SKIP] labels for ${TAG} seem to exist"
          else
            python scripts/build_labels.py \
              --profit-target "${PROFIT_TARGET}" \
              --max-days "${HOLDING_DAYS}" \
              --stop-level "${STOP_LEVEL}"
          fi

      - name: Build strategy labels - if missing for TAG
        run: |
          mkdir -p data/labels
          if ls data/labels 2>/dev/null | grep -q "${TAG}"; then
            echo "[SKIP] strategy labels for ${TAG} seem to exist"
          else
            python scripts/build_strategy_labels.py \
              --profit-target "${PROFIT_TARGET}" \
              --max-days "${HOLDING_DAYS}" \
              --stop-level "${STOP_LEVEL}" \
              --max-extend-days "${MAX_EXTEND_DAYS}"
          fi

      # ---- models: pkl 있으면 스킵
      - name: Train success model - if missing
        run: |
          if [ -f app/model.pkl ] && [ -f app/scaler.pkl ]; then
            echo "[SKIP] success model already exists"
          else
            python scripts/train_model.py
          fi

      - name: Train strategy models (tail etc) - if missing
        run: |
          if [ -f app/tail_model.pkl ] && [ -f app/tail_scaler.pkl ]; then
            echo "[SKIP] tail model already exists"
          else
            python scripts/train_strategy_models.py
          fi

      # ---- ✅ 게이트 조합 실험 ----
      - name: Gate grid runs (none / tail / utility / tail_utility) x (lists)
        run: |
          set -euo pipefail

          PT="${PROFIT_TARGET}"
          H="${HOLDING_DAYS}"
          SL="${STOP_LEVEL}"
          EX="${MAX_EXTEND_DAYS}"
          LAM="${LAMBDA_TAIL}"

          IFS=',' read -ra TAILS <<< "${TAIL_MAX_LIST}"
          IFS=',' read -ra UQS   <<< "${U_QUANTILE_LIST}"
          IFS=',' read -ra RANKS <<< "${RANK_BY_LIST}"

          trim () { echo "$1" | xargs; }
          safe () { echo "$1" | sed 's/\./p/g' | sed 's/-/m/g'; }

          run_one () {
            local MODE="$1"
            local TMAX="$2"
            local UQ="$3"
            local RANK="$4"

            local TMAX_T="$(safe "$(trim "$TMAX")")"
            local UQ_T="$(safe "$(trim "$UQ")")"
            local RANK_T="$(trim "$RANK")"

            local SUFFIX="${MODE}_t${TMAX_T}_q${UQ_T}_r${RANK_T}"

            echo ""
            echo "=============================="
            echo "[RUN] mode=${MODE} tail_max=${TMAX} u_q=${UQ} rank_by=${RANK} suffix=${SUFFIX}"
            echo "=============================="

            python scripts/predict_gate.py \
              --profit-target "${PT}" \
              --max-days "${H}" \
              --stop-level "${SL}" \
              --max-extend-days "${EX}" \
              --gate-mode "${MODE}" \
              --tail-max "$(trim "$TMAX")" \
              --u-quantile "$(trim "$UQ")" \
              --rank-by "${RANK_T}" \
              --lambda-tail "${LAM}" \
              --out-suffix "${SUFFIX}"

            python scripts/simulate_single_position_engine.py \
              --profit-target "${PT}" \
              --max-days "${H}" \
              --stop-level "${SL}" \
              --max-extend-days "${EX}" \
              --method custom \
              --pick-col pick_custom \
              --picks-path "data/signals/picks_${TAG}_gate_${SUFFIX}.csv" \
              --label "${SUFFIX}" \
              --out-suffix "${SUFFIX}" \
              --initial-seed 40000000
          }

          # baseline(none): 각 rank_by마다 1회(첫 tail/u 사용)
          BASE_T="${TAILS[0]}"
          BASE_Q="${UQS[0]}"
          for R in "${RANKS[@]}"; do
            run_one "none" "${BASE_T}" "${BASE_Q}" "${R}"
          done

          # tail gate: tail list x rank
          for T in "${TAILS[@]}"; do
            for R in "${RANKS[@]}"; do
              run_one "tail" "${T}" "${BASE_Q}" "${R}"
            done
          done

          # utility gate: u list x rank
          for Q in "${UQS[@]}"; do
            for R in "${RANKS[@]}"; do
              run_one "utility" "${BASE_T}" "${Q}" "${R}"
            done
          done

          # tail+utility: tail x u x rank
          for T in "${TAILS[@]}"; do
            for Q in "${UQS[@]}"; do
              for R in "${RANKS[@]}"; do
                run_one "tail_utility" "${T}" "${Q}" "${R}"
              done
            done
          done

      - name: Merge gate summaries
        run: |
          python scripts/merge_gate_summaries.py --tag "${TAG}"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: gate-results
          path: |
            data/signals/**
            data/features/**
            data/labels/**
            data/raw/**
            app/**
