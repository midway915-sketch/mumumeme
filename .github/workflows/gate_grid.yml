name: gate-grid

on:
  workflow_dispatch:
    inputs:
      profit_target:
        description: "profit target (e.g. 0.10)"
        required: true
        default: "0.10"
      max_days:
        description: "max holding days (e.g. 40)"
        required: true
        default: "40"
      stop_level:
        description: "stop level (e.g. -0.10)"
        required: true
        default: "-0.10"
      max_extend_days:
        description: "extend horizon tag + strategy label horizon add (e.g. 30)"
        required: true
        default: "30"
      p_tail_thresholds:
        description: "comma-separated p_tail thresholds (e.g. 0.15,0.25,0.35)"
        required: true
        default: "0.20,0.30"
      utility_quantiles:
        description: "comma-separated utility quantiles (e.g. 0.60,0.75,0.90)"
        required: true
        default: "0.75,0.90"
      rank_metrics:
        description: "comma-separated rank metric (utility|ret_score|p_success). e.g. utility,ret_score"
        required: true
        default: "ret_score"
      lambda_tail:
        description: "utility tail penalty lambda (e.g. 0.05)"
        required: true
        default: "0.05"
      rebuild_all:
        description: "true to rebuild prices/features/labels/models from scratch"
        required: true
        default: "false"

  schedule:
    - cron: "10 23 * * *"

jobs:
  grid:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas numpy yfinance pyarrow scikit-learn joblib
          fi

      - name: Ensure folders
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/raw data/features data/labels data/signals data/meta app scripts data/_backup

      - name: Set LABEL_SPEC env
        shell: bash
        run: |
          set -euo pipefail
          echo "LABEL_SPEC=pt=${{ inputs.profit_target }}_h=${{ inputs.max_days }}_sl=${{ inputs.stop_level }}_ex=${{ inputs.max_extend_days }}" >> $GITHUB_ENV

      # ---- PRICES cache
      - name: Restore cache (PRICES)
        uses: actions/cache@v4
        with:
          path: |
            data/raw/prices.parquet
            data/raw/prices.csv
            data/raw/prices_meta.json
          key: mumumeme-prices-v2-${{ runner.os }}-${{ hashFiles('data/universe.csv','scripts/universe.py','scripts/fetch_prices.py') }}
          restore-keys: |
            mumumeme-prices-v2-${{ runner.os }}-

      # ---- FEATURES cache
      - name: Restore cache (FEATURES_MODEL)
        uses: actions/cache@v4
        with:
          path: |
            data/features/features_model.parquet
            data/features/features_model.csv
          key: mumumeme-features-v2-${{ runner.os }}-${{ hashFiles('data/universe.csv','scripts/universe.py','scripts/fetch_prices.py','scripts/build_features.py','scripts/build_ev_features.py','scripts/merge_incremental_table.py') }}
          restore-keys: |
            mumumeme-features-v2-${{ runner.os }}-

      # ---- LABELS+MODELS cache (success + tau together)
      - name: Restore cache (LABELS+MODELS)
        uses: actions/cache@v4
        with:
          path: |
            data/labels/labels_model.parquet
            data/labels/labels_model.csv
            data/labels/labels_tau.parquet
            data/labels/labels_tau.csv
            app/model.pkl
            app/scaler.pkl
            app/tau_model.pkl
            app/tau_scaler.pkl
            data/meta/build_fingerprint.json
          key: mumumeme-models-v3-${{ runner.os }}-${{ env.LABEL_SPEC }}-${{ hashFiles('scripts/build_labels.py','scripts/train_model.py','scripts/build_tau_labels.py','scripts/train_tau_model.py','scripts/check_rebuild.py','scripts/merge_incremental_table.py') }}
          restore-keys: |
            mumumeme-models-v3-${{ runner.os }}-

      - name: Prepare required files (daily incremental)
        shell: bash
        env:
          REBUILD_ALL: ${{ inputs.rebuild_all }}
          PROFIT_TARGET: ${{ inputs.profit_target }}
          MAX_DAYS: ${{ inputs.max_days }}
          STOP_LEVEL: ${{ inputs.stop_level }}
        run: |
          set -euo pipefail

          if [ "$REBUILD_ALL" = "true" ]; then
            rm -rf data/raw/* data/features/* data/labels/* data/signals/* app/* data/meta/* || true
          fi

          # 1) prices
          python scripts/universe.py
          if [ ! -f data/raw/prices.parquet ] && [ ! -f data/raw/prices.csv ]; then
            python scripts/fetch_prices.py --include-extra --reset --force-full --max-years 11
          else
            python scripts/fetch_prices.py --include-extra --lookback-days 10 --max-years 11
          fi

          # 2) features (없으면 full)
          if [ ! -f data/features/features_model.parquet ] && [ ! -f data/features/features_model.csv ]; then
            python scripts/build_features.py
          fi

          # 3) labels (success)
          if [ ! -f data/labels/labels_model.parquet ] && [ ! -f data/labels/labels_model.csv ]; then
            python scripts/build_labels.py \
              --profit-target "$PROFIT_TARGET" \
              --max-days "$MAX_DAYS" \
              --stop-level "$STOP_LEVEL"
          fi

          # 4) tau labels
          if [ ! -f data/labels/labels_tau.parquet ] && [ ! -f data/labels/labels_tau.csv ]; then
            python scripts/build_tau_labels.py \
              --profit-target "$PROFIT_TARGET" \
              --max-days "$MAX_DAYS" \
              --stop-level "$STOP_LEVEL" \
              --max-extend-days "$MAX_EXTEND_DAYS" \
              --k1 10 \
              --k2 20
          fi

          # 5) train models if missing
          if [ ! -f app/model.pkl ] || [ ! -f app/scaler.pkl ]; then
            python scripts/train_model.py
          fi

          if [ ! -f app/tau_model.pkl ] || [ ! -f app/tau_scaler.pkl ]; then
            python scripts/train_tau_model.py
          fi

      - name: Run gate grid (predict + simulate + summarize)
        shell: bash
        env:
          PROFIT_TARGET: ${{ inputs.profit_target }}
          MAX_DAYS: ${{ inputs.max_days }}
          STOP_LEVEL: ${{ inputs.stop_level }}
          MAX_EXTEND_DAYS: ${{ inputs.max_extend_days }}
          P_TAIL_THRESHOLDS: ${{ inputs.p_tail_thresholds }}
          UTILITY_QUANTILES: ${{ inputs.utility_quantiles }}
          RANK_METRICS: ${{ inputs.rank_metrics }}
          LAMBDA_TAIL: ${{ inputs.lambda_tail }}
          GATE_MODES: "none,tail,utility,tail_utility"
        run: |
          set -euo pipefail
          chmod +x scripts/run_grid_workflow.sh || true
          bash scripts/run_grid_workflow.sh

      - name: Aggregate summaries
        shell: bash
        run: |
          set -euo pipefail
          python scripts/aggregate_gate_grid.py \
            --signals-dir "data/signals" \
            --out-aggregate "data/signals/gate_grid_aggregate.csv" \
            --out-top "data/signals/gate_grid_top_by_recent10y.csv" \
            --pattern "gate_summary_*.csv" \
            --topn 30

      - name: Upload artifacts (signals + meta + models)
        uses: actions/upload-artifact@v4
        with:
          name: gate-grid-results
          path: |
            data/meta/build_fingerprint.json
            data/labels/labels_model.*
            data/labels/labels_tau.*
            app/model.pkl
            app/scaler.pkl
            app/tau_model.pkl
            app/tau_scaler.pkl
            data/signals/gate_summary_*.csv
            data/signals/gate_grid_aggregate.csv
            data/signals/gate_grid_top_by_recent10y.csv
            data/signals/picks_*.csv
            data/signals/sim_engine_trades_*.parquet
            data/signals/sim_engine_curve_*.parquet
          if-no-files-found: error